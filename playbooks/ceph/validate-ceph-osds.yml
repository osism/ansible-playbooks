---
###
# This playbook checks the following Ceph components
# inside a OSISM-deployed Ceph cluster:
# OSD services:
# Tests:
# - All containers with OSDs are existing
# - All containers with OSDs are running
# - Old LVM2 approach: Count of OSDs on each ceph-osd node == devices * osds_per_device
# - New LVM2 approach: Count of OSDs on each ceph-osd node == ceph_osd_devices
# - OSDs are up+in
# - OSDs are encrypted if dmcrypt is true and not encrypted otherwise
# - OSDs are placed correctly in OSD tree
#
# This playbook can be used to validate that basic ceph
# cluster functionality is present and in sync with config.
# To check other components use the other playbooks.
# This playbook will create a JSON report file on
# the first OSISM manager node inside /opt/reports/validator
###

- name: Ceph validate OSDs
  hosts: ceph-osd
  strategy: linear
  gather_facts: true
  force_handlers: true


  vars:
    _osds_reports_directory: "/opt/reports/validator"

  tasks:
    # ansible_date_time is cached between runs,
    # so we need to get a timestamp another way
    - name: Get timestamp for report file
      ansible.builtin.command:
        cmd: "date --iso-8601=seconds"
      register: _osds_report_timestamp
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      changed_when: false

    - name: Get extra vars for Ceph configuration
      ansible.builtin.include_vars:
        file:
          "{{ configuration_directory }}\
          /environments/ceph/configuration.yml"
        name: _osds_configuration_vars
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    - name: Create report output directory
      become: true
      ansible.builtin.file:
        path: "{{ _osds_reports_directory }}"
        state: directory
        owner: "{{ operator_user }}"
        group: "{{ operator_group }}"
        recurse: true
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    - name: Define report vars
      ansible.builtin.set_fact:
        _osds_report_file:
          "{{ _osds_reports_directory }}\
           /ceph-osds-validator-\
           {{ _osds_report_timestamp.stdout | trim }}\
           -report.json"
        _osds_test_failed: false
        _osds_result: "no-result"
        _osds_reasons: ""
        _osds_tests: []
      run_once: true

    - name: Prepare OSD test variables for old LVM2 approach  # noqa osism-fqcn
      block:
        - name: Define OSD test variables
          ansible.builtin.set_fact:
            _osds_node_count: "{{ groups['ceph-osd'] | length }}"
            _osds_count_total: 0
            _osds_count_by_host: 0
            _osds_num_per_device:
              "{{ _osds_configuration_vars['osds_per_device'] | default(1) }}"
            _osds_dmcrypt:
              "{{ _osds_configuration_vars['dmcrypt'] }}"
            _osds_container_test_data: []
          run_once: true

        - name: Calculate OSD devices for each host
          ansible.builtin.set_fact:
            _osds_count_by_host:
              "{{ (_osds_num_per_device | int) * (devices | length) }}"
      when:
        - devices is defined

    - name: Prepare OSD test variables for new LVM2 approach  # noqa osism-fqcn
      block:
        - name: Define OSD test variables
          ansible.builtin.set_fact:
            _osds_node_count: "{{ groups['ceph-osd'] | length }}"
            _osds_count_total: 0
            _osds_count_by_host: 0
            _osds_num_per_device: 1
            _osds_dmcrypt:
              "{{ _osds_configuration_vars['dmcrypt'] }}"
            _osds_container_test_data: []
          run_once: true

        - name: Calculate OSD devices for each host
          ansible.builtin.set_fact:
            _osds_count_by_host:
              "{{ (_osds_num_per_device | int) * (ceph_osd_devices | length) }}"
      when:
        - devices is not defined

    - name: Calculate total number of OSDs in cluster
      ansible.builtin.set_fact:
        _osds_count_total:
          "{{
             play_hosts |
             map('extract', hostvars, '_osds_count_by_host') |
             map('int') |
             sum
           }}"
      run_once: true

    # START OF TESTS SECTION

    # Test 1: Check number of OSD containers equals calculated number
    - name: Prepare test data
      ansible.builtin.set_fact:
        _osds_test_containers_count_result: "no-result"
        _osds_test_containers_count_data: ""

    - name: Get list of ceph-osd containers on host
      ansible.builtin.set_fact:
        _osds_containers:
          "{{ _osds_containers | default([]) +
              [{'name': item.name.split('/')[1],
                'osd_id': item.name.split('-')[2],
                'state': item.state}]
           }}"
      when: "item.name is match('/ceph-osd.*')"
      with_items:
        - "{{ ansible_facts['ansible_local']['docker_containers'] }}"

    - name: Get count of ceph-osd containers on host
      ansible.builtin.set_fact:
        _osds_containers_not_running: []
        _osds_num_containers: "{{ _osds_containers | length }}"

    # Fail test if count does not match on a host
    - name: Set test result to failed when count of containers is wrong
      ansible.builtin.set_fact:
        _osds_test_failed: true
        _osds_test_containers_count_result: "failed"
        _osds_test_containers_count_data:
          "OSD Container count mismatch on {{ inventory_hostname }}.\n\
           Expected count: {{ _osds_count_by_host }} \n\
           Actual count: {{ _osds_num_containers }}"
        _osds_reasons:
          "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
           Test 'containers-count' failed on
           {{ inventory_hostname }}."
      when: _osds_num_containers | int != (_osds_count_by_host | int)

    # Pass test if count matches
    - name: Set test result to passed if count matches
      ansible.builtin.set_fact:
        _osds_test_containers_count_result: "passed"
        _osds_test_containers_count_data:
          "OSD Container count matches on {{ inventory_hostname }}. \n\
           Expected count: {{ _osds_count_by_host }} \n\
           Actual count: {{ _osds_num_containers }}"
      when: _osds_num_containers | int == (_osds_count_by_host | int)

    # Test 2: Check that all OSD containers are running
    - name: Prepare test data
      ansible.builtin.set_fact:
        _osds_test_containers_running_result: "no-result"
        _osds_test_containers_running_data: ""

    - name: Get list of ceph-osd containers that are not running
      ansible.builtin.set_fact:
        _osds_containers_not_running:
          "{{ _osds_containers_not_running + [item.name] }}"
      when: "item.state != 'running'"
      with_items:
        - "{{ _osds_containers }}"

    - name: Get count of ceph-osd containers that are not running
      ansible.builtin.set_fact:
        _osds_num_containers_not_running:
          "{{ _osds_containers_not_running | length }}"

    # Singular error message
    - name: Set test result to failed if an OSD is not running
      ansible.builtin.set_fact:
        _osds_test_failed: true
        _osds_test_containers_running_result: "failed"
        _osds_test_containers_running_data:
          "{{ _osds_num_containers_not_running }} container
           is not running on {{ inventory_hostname }}:\n
           {{ _osds_containers_not_running | join(',\n') }}"
        _osds_reasons:
          "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
           Test 'containers-running' failed on
           {{ inventory_hostname }}."
      when: _osds_num_containers_not_running | int == 1

    # Plural error message
    - name: Set test result to failed if an OSD is not running
      ansible.builtin.set_fact:
        _osds_test_failed: true
        _osds_test_containers_running_result: "failed"
        _osds_test_containers_running_data:
          "{{ _osds_num_containers_not_running }} containers
           are not running on {{ inventory_hostname }}:\n
           {{ _osds_containers_not_running | join(',\n') }}"
        _osds_reasons:
          "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
           Test 'containers-running' failed on
           {{ inventory_hostname }}."
      when: _osds_num_containers_not_running | int > 1

    # Pass test if all containers are running
    - name: Set test result to passed if all containers are running
      ansible.builtin.set_fact:
        _osds_test_containers_running_result: "passed"
        _osds_test_containers_running_data:
          "OSD Containers on {{ inventory_hostname }}: \n\
           Running: {{ _osds_num_containers }}\n\
           List: {{ _osds_containers }}"
      when: _osds_num_containers_not_running | int == 0

    # I bail out early here if one of the two container tests failed
    # as it indicates a major problem and could be problematic
    # when trying to run the other tests. It's simpler to bail
    # out early than having to code around missing containers etc.
    - name: Fail and bail out early due to critical test failure(s)  # noqa osism-fqcn
      block:
        # We need to aggregate the test data from the different nodes
        # into one variable that gets written to the report because
        # of the way ansible handles facts across hosts.
        # This is split into multiple steps as apparently you can't
        # just use a fact you just set in the same set_fact task.
        - name: Aggregate test results step one
          ansible.builtin.set_fact:
            _osds_test_containers_count_data:
              "{{
                 play_hosts |
                 map(\
                     'extract',
                     hostvars,
                     '_osds_test_containers_count_data'\
                    )
               }}"

            _osds_test_containers_running_data:
              "{{
                 play_hosts |
                 map(\
                     'extract',
                     hostvars,
                     '_osds_test_containers_running_data'\
                    )
               }}"
            _osds_reasons:
              "{{
                 play_hosts |
                 map(\
                     'extract',
                     hostvars,
                     '_osds_reasons'\
                    ) |
                 join('\n')
                 + '\nSee test data for details.'
               }}"
          run_once: true
          delegate_to: "{{ groups['manager'][0] }}"

        - name: Aggregate test results step two
          ansible.builtin.set_fact:
            _osds_result: "failed"
            _osds_tests:
              - {
                name: "containers-count",
                result: "{{ _osds_test_containers_count_result }}",
                data: "{{ _osds_test_containers_count_data }}"
              }
              - {
                name: "containers-running",
                result: "{{ _osds_test_containers_running_result }}",
                data: "{{ _osds_test_containers_running_data }}"
              }
          run_once: true
          delegate_to: "{{ groups['manager'][0] }}"

        - name: Aggregate test results step three
          ansible.builtin.set_fact:
            _validator_data:
              validator: "ceph-osds"
              validator_result: "{{ _osds_result }}"
              validator_reason: "{{ _osds_reasons }}"
              validator_tests: "{{ _osds_tests }}"
          run_once: true
          delegate_to: "{{ groups['manager'][0] }}"
          changed_when: true
          notify:
            - Write report file
      when: _osds_test_failed

    # Flush handlers to write report file
    - name: Flush handlers
      ansible.builtin.meta: flush_handlers
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    # Print where to find report file
    - name: Print report file information
      ansible.builtin.debug:
        msg:
          - "Validator run completed."
          - "You can find the report file here:"
          - "{{ _osds_report_file }}"
          - "on the following host:"
          - "{{ groups['manager'][0] }}"
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      when: _osds_test_failed

    # Abort playbook execution after writing report
    - name: Fail early due to containers not running
      ansible.builtin.fail:
        msg: "Critical tests failed. See report file for details."
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      when: _osds_test_failed

    # Test 3: Check all OSDs are up+in
    - name: Prepare test data
      ansible.builtin.set_fact:
        _osds_test_up_in_result: "no-result"
        _osds_test_up_in_data: ""

    - name: Get ceph osd tree
      community.docker.docker_container_exec:
        container: "{{ _osds_containers[0].name }}"
        command: "ceph osd tree --format=json"
      register: _osds_tree_raw
      run_once: true
      delegate_to: "{{ groups[mon_group_name | default('ceph-mon')][0] }}"

    - name: Parse osd tree from JSON
      ansible.builtin.set_fact:
        _osds_tree: "{{ _osds_tree_raw.stdout | from_json }}"
      run_once: true

    - name: Get OSDs that are not up or in
      ansible.builtin.set_fact:
        _osds_not_up:
          "{{ _osds_tree |
              json_query('nodes[?type == `osd` && status != `up`]')
           }}"
        _osds_not_in:
          "{{
              _osds_tree |
              json_query('nodes[?type == `osd` && reweight == `0`]')
           }}"
      run_once: true

    - name: Fail test if OSDs are not up or in
      ansible.builtin.set_fact:
        _osds_test_failed: true
        _osds_test_up_in_result: "failed"
        _osds_test_up_in_data:
          "Not all OSDs are up+in.\n\
           Number of OSDs not in status 'up':
           {{ _osds_not_up | length }}\n\
           Number of OSDs with reweight 0 (equals 'out'):
           {{ _osds_not_in | length }}\n\
           OSDs not 'up':\n\
           {{ _osds_not_up }}\n\n\n\n\
           OSDs not 'in':\n\
           {{ _osds_not_in }}"
        _osds_reasons:
          "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
          Test 'osds-up-in' failed."
      run_once: true
      when: _osds_not_up | length != 0 or _osds_not_in | length != 0

    - name: Pass test if OSDs are all up and in
      ansible.builtin.set_fact:
        _osds_test_up_in_result: "passed"
        _osds_test_up_in_data: "All OSDs appear to be up+in."
      run_once: true
      when:
        - _osds_not_up | length == 0
        - _osds_not_in | length == 0

    # Test 4: Check if OSD encryption is enabled/disabled according
    # to configuration.
    - name: Prepare test data
      ansible.builtin.set_fact:
        _osds_test_encryption_result: "no-result"
        _osds_test_encryption_data: ""

    - name: List ceph LVM volumes and collect data
      community.docker.docker_container_exec:
        container: "{{ _osds_containers[0].name }}"
        command: "ceph-volume lvm list --format=json"
      register: _osds_lvm_volumes_raw

    - name: Parse LVM data as JSON
      ansible.builtin.set_fact:
        _osds_lvm_volumes:
          "{{ _osds_lvm_volumes_raw.stdout | from_json }}"
        _osds_encrypted_query:
          '*[?tags."ceph.encrypted"==''1''].tags."ceph.osd_id"[]'
        _osds_unencrypted_query:
          '*[?tags."ceph.encrypted"==''0''].tags."ceph.osd_id"[]'

    - name: Get unencrypted and encrypted OSDs
      ansible.builtin.set_fact:
        _osds_encrypted:
          "{{ _osds_lvm_volumes |
              json_query(_osds_encrypted_query)
           }}"
        _osds_unencrypted:
          "{{ _osds_lvm_volumes |
              json_query(_osds_unencrypted_query)
           }}"

    # If dmcrypt is set to true check that everything is encrypted
    - name: Check if every OSD is encrypted that is found  # noqa osism-fqcn
      block:
        - name: Fail if count of encrypted OSDs does not match
          ansible.builtin.set_fact:
            _osds_test_failed: true
            _osds_test_encryption_result: "failed"
            _osds_test_encryption_data:
              "Encryption is enabled in configuration, however
               the number of encrypted OSDs found with
               ceph-volume lvm list on {{ inventory_hostname }}
               does not equal the number of OSDs expected.\n\
               Encrypted OSDs on this node:\n\
               {{ _osds_encrypted }}
               Unencrypted OSDs on this node:\n\
               {{ _osds_unencrypted }}"
            _osds_reasons:
              "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
              Test 'osds-dmcrypt' failed."
          when: _osds_encrypted | length != _osds_count_by_host | int

        - name: Pass if count of encrypted OSDs equals count of OSDs
          ansible.builtin.set_fact:
            _osds_test_encryption_result: "passed"
            _osds_test_encryption_data:
              "All active OSDs on {{ inventory_hostname }}
               appear to use encryption.\n\
               {% if _osds_unencrypted | length > 0 %}\
               However the following additional unencrypted OSDs
               were found:\n\
               {{ _osds_unencrypted }}
               {% endif %}\
               # of OSDs per host: {{ _osds_count_by_host }}\n\
               # of OSDs encrypted: {{ _osds_encrypted | length }}\n\
               # of OSDs unencrypted: {{ _osds_unencrypted | length }}"
          when:
            - _osds_encrypted | length == _osds_count_by_host | int
      when: _osds_dmcrypt

    # If dmcrypt is set to false check that everything is not encrypted
    - name: Check if every OSD is not encrypted that is found  # noqa osism-fqcn
      block:
        - name: Fail if count of unencrypted OSDs does not match
          ansible.builtin.set_fact:
            _osds_test_failed: true
            _osds_test_encryption_result: "failed"
            _osds_test_encryption_data:
              "Encryption is disabled in configuration, however
               the number of unencrypted OSDs found with
               ceph-volume lvm list on {{ inventory_hostname }}
               does not equal the number of OSDs expected.\n\
               Encrypted OSDs on this node:\n\
               {{ _osds_encrypted }}
               Unencrypted OSDs on this node:\n\
               {{ _osds_unencrypted }}"
            _osds_reasons:
              "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
              Test 'osds-dmcrypt' failed."
          when: _osds_unencrypted | length != _osds_count_by_host | int

        - name: Pass if count of unencrypted OSDs equals count of OSDs
          ansible.builtin.set_fact:
            _osds_test_encryption_result: "passed"
            _osds_test_encryption_data:
              "All active OSDs on {{ inventory_hostname }}
               appear to not use encryption.\n\
               {% if _osds_encrypted | length > 0 %}\
               However the following additional encrypted OSDs
               were found:\n\
               {{ _osds_encrypted }}
               {% endif %}\
               # of OSDs per host: {{ _osds_count_by_host }}\n\
               # of OSDs encrypted: {{ _osds_encrypted | length }}\n\
               # of OSDs unencrypted: {{ _osds_unencrypted | length }}"
          when:
            - _osds_unencrypted | length == _osds_count_by_host | int
      when: not _osds_dmcrypt

    # Test 5: Check that all active OSDs are in the correct CRUSH
    # location
    - name: Prepare test data
      ansible.builtin.set_fact:
        _osds_test_crush_location_result: "no-result"
        _osds_test_crush_location_data: ""
        _osds_containers_osd_ids:
          "{{
              _osds_containers |
              json_query('[*].osd_id') |
              map('int') |
              list
           }}"
        _osds_crush_node_data_query:
          "nodes[?type == `host` && name == `\
           {{ inventory_hostname_short }}`]"
        _osds_crush_root_node_data_query:
          "nodes[?type == `root` && name == `default`]"

    - name: Get CRUSH node data of each OSD host and root node childs
      ansible.builtin.set_fact:
        _osds_crush_node_data:
          "{{ _osds_tree |
              json_query(_osds_crush_node_data_query)
           }}"
        _osds_crush_root_node_data:
          "{{ _osds_tree |
              json_query(_osds_crush_root_node_data_query)
           }}"

    # This checks the following:
    # - each host is inside the default root
    # - the OSD IDs found running on the each host are children of it
    # - the children in CRUSH map of each host are running on the host
    # Any discrepancy here is likely the result of a failed deployment.
    - name: Calculate sub test expression results
      ansible.builtin.set_fact:
        _osds_is_child_of_root:
          "{{ _osds_crush_node_data[0].id in
              _osds_crush_root_node_data[0].children }}"
        _osds_running_not_in_crushmap:
          "{{
              _osds_containers_osd_ids |
              difference(_osds_crush_node_data[0].children)
           }}"
        _osds_crushmap_not_in_running:
          "{{
              _osds_crush_node_data[0].children |
              difference(_osds_containers_osd_ids)
           }}"

    - name: Fail test if any sub test failed
      ansible.builtin.set_fact:
        _osds_test_failed: true
        _osds_test_crush_location_result: "failed"
        _osds_test_crush_location_data:
          "Test failed on node {{ inventory_hostname }}. Reasons:\n
           {% if not _osds_is_child_of_root %}
           - Host is not child of default root.
           {% endif %}
           {% if _osds_running_not_in_crushmap | length != 0 %}
           - The following OSDs are found running on the host,\n
             but are not children of the host in CRUSH map:\n
             {{ _osds_running_not_in_crushmap }}
           {% endif %}
           {% if _osds_crushmap_not_in_running | length != 0 %}
           - The following OSDs are found as children in CRUSH
             of the host,\n
             but are not running on the host:\n
             {{ _osds_crushmap_not_in_running }}
           {% endif %}"
        _osds_reasons:
          "{{ _osds_reasons }}{{ ' ' if _osds_reasons }}\
          Test 'osds-crush-location' failed."
      when: not _osds_is_child_of_root or
        _osds_running_not_in_crushmap | length != 0 or
        _osds_crushmap_not_in_running | length != 0

    - name: Pass test if no sub test failed
      ansible.builtin.set_fact:
        _osds_test_crush_location_result: "passed"
        _osds_test_crush_location_data:
          "CRUSH tree locations for node {{ inventory_hostname }}
           and its OSDs appear to be in order."
      when:
        - _osds_is_child_of_root
        - _osds_running_not_in_crushmap | length == 0
        - _osds_crushmap_not_in_running | length == 0

    # END OF TESTS SECTION

    # Set validation result to passed if no test failed
    - name: Set validation result to passed if no test failed
      ansible.builtin.set_fact:
        _osds_result: "passed"
        _osds_reasons:
          "All tests passed validation."
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      when: not _osds_test_failed

    # Set validation result to failed if a test failed
    - name: Set validation result to failed if a test failed
      ansible.builtin.set_fact:
        _osds_result: "failed"
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      when: _osds_test_failed

    # Aggregate results for report file
    - name: Aggregate test results step one
      ansible.builtin.set_fact:
        _osds_test_containers_count_data:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_test_containers_count_data'\
                 )
            }}"

        _osds_test_containers_running_data:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_test_containers_running_data'\
                 )
            }}"
        _osds_test_up_in_data:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_test_up_in_data'\
                 ) |
              unique
            }}"
        _osds_test_encryption_data:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_test_encryption_data'\
                 ) |
              unique
            }}"
        _osds_test_crush_location_data:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_test_crush_location_data'\
                 ) |
              unique
            }}"
        _osds_reasons:
          "{{
              play_hosts |
              map(\
                  'extract',
                  hostvars,
                  '_osds_reasons'\
                 ) |
              unique |
              join('\n')
              + '\nSee test data for details.'
            }}"
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    - name: Aggregate test results step two
      ansible.builtin.set_fact:
        _osds_tests:
          - {
            name: "containers-count",
            result: "{{ _osds_test_containers_count_result }}",
            data: "{{ _osds_test_containers_count_data }}"
          }
          - {
            name: "containers-running",
            result: "{{ _osds_test_containers_running_result }}",
            data: "{{ _osds_test_containers_running_data }}"
          }
          - {
            name: "osds-up-in",
            result: "{{ _osds_test_up_in_result }}",
            data: "{{ _osds_test_up_in_data }}"
          }
          - {
            name: "osds-dmcrypt",
            result: "{{ _osds_test_encryption_result }}",
            data: "{{ _osds_test_encryption_data }}"
          }
          - {
            name: "osds-crush-location",
            result: "{{ _osds_test_crush_location_result }}",
            data: "{{ _osds_test_crush_location_data }}"
          }
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    - name: Aggregate test results step three
      ansible.builtin.set_fact:
        _validator_data:
          validator: "ceph-osds"
          validator_result: "{{ _osds_result }}"
          validator_reason: "{{ _osds_reasons }}"
          validator_tests: "{{ _osds_tests }}"
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
      changed_when: true
      notify:
        - Write report file

    # Flush handlers to write report file
    - name: Flush handlers
      ansible.builtin.meta: flush_handlers
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"

    # Print where to find report file
    - name: Print report file information
      ansible.builtin.debug:
        msg:
          - "Validator run completed."
          - "You can find the report file here:"
          - "{{ _osds_report_file }}"
          - "on the following host:"
          - "{{ groups['manager'][0] }}"
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
  handlers:
    - name: Write report file
      ansible.builtin.template:
        src: "templates/ceph-osds-validator-report.json.j2"
        dest: "{{ _osds_report_file }}"
        mode: 0640
      run_once: true
      delegate_to: "{{ groups['manager'][0] }}"
